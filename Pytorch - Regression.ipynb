{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc2b4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8a58bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8e9d4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7695cc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07450709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.32520000e+00  4.10000000e+01  6.98412698e+00  1.02380952e+00\n",
      "   3.22000000e+02  2.55555556e+00  3.78800000e+01 -1.22230000e+02]\n",
      " [ 8.30140000e+00  2.10000000e+01  6.23813708e+00  9.71880492e-01\n",
      "   2.40100000e+03  2.10984183e+00  3.78600000e+01 -1.22220000e+02]\n",
      " [ 7.25740000e+00  5.20000000e+01  8.28813559e+00  1.07344633e+00\n",
      "   4.96000000e+02  2.80225989e+00  3.78500000e+01 -1.22240000e+02]\n",
      " [ 5.64310000e+00  5.20000000e+01  5.81735160e+00  1.07305936e+00\n",
      "   5.58000000e+02  2.54794521e+00  3.78500000e+01 -1.22250000e+02]\n",
      " [ 3.84620000e+00  5.20000000e+01  6.28185328e+00  1.08108108e+00\n",
      "   5.65000000e+02  2.18146718e+00  3.78500000e+01 -1.22250000e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "172e9cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.526 3.585 3.521 3.413 3.422]\n"
     ]
    }
   ],
   "source": [
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d065cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6645a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "n_epochs = 20  # number of epochs to run\n",
    "batch_size = 32  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e4bf62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,    32,    64,    96,   128,   160,   192,   224,   256,   288,\n",
       "          320,   352,   384,   416,   448,   480,   512,   544,   576,   608,\n",
       "          640,   672,   704,   736,   768,   800,   832,   864,   896,   928,\n",
       "          960,   992,  1024,  1056,  1088,  1120,  1152,  1184,  1216,  1248,\n",
       "         1280,  1312,  1344,  1376,  1408,  1440,  1472,  1504,  1536,  1568,\n",
       "         1600,  1632,  1664,  1696,  1728,  1760,  1792,  1824,  1856,  1888,\n",
       "         1920,  1952,  1984,  2016,  2048,  2080,  2112,  2144,  2176,  2208,\n",
       "         2240,  2272,  2304,  2336,  2368,  2400,  2432,  2464,  2496,  2528,\n",
       "         2560,  2592,  2624,  2656,  2688,  2720,  2752,  2784,  2816,  2848,\n",
       "         2880,  2912,  2944,  2976,  3008,  3040,  3072,  3104,  3136,  3168,\n",
       "         3200,  3232,  3264,  3296,  3328,  3360,  3392,  3424,  3456,  3488,\n",
       "         3520,  3552,  3584,  3616,  3648,  3680,  3712,  3744,  3776,  3808,\n",
       "         3840,  3872,  3904,  3936,  3968,  4000,  4032,  4064,  4096,  4128,\n",
       "         4160,  4192,  4224,  4256,  4288,  4320,  4352,  4384,  4416,  4448,\n",
       "         4480,  4512,  4544,  4576,  4608,  4640,  4672,  4704,  4736,  4768,\n",
       "         4800,  4832,  4864,  4896,  4928,  4960,  4992,  5024,  5056,  5088,\n",
       "         5120,  5152,  5184,  5216,  5248,  5280,  5312,  5344,  5376,  5408,\n",
       "         5440,  5472,  5504,  5536,  5568,  5600,  5632,  5664,  5696,  5728,\n",
       "         5760,  5792,  5824,  5856,  5888,  5920,  5952,  5984,  6016,  6048,\n",
       "         6080,  6112,  6144,  6176,  6208,  6240,  6272,  6304,  6336,  6368,\n",
       "         6400,  6432,  6464,  6496,  6528,  6560,  6592,  6624,  6656,  6688,\n",
       "         6720,  6752,  6784,  6816,  6848,  6880,  6912,  6944,  6976,  7008,\n",
       "         7040,  7072,  7104,  7136,  7168,  7200,  7232,  7264,  7296,  7328,\n",
       "         7360,  7392,  7424,  7456,  7488,  7520,  7552,  7584,  7616,  7648,\n",
       "         7680,  7712,  7744,  7776,  7808,  7840,  7872,  7904,  7936,  7968,\n",
       "         8000,  8032,  8064,  8096,  8128,  8160,  8192,  8224,  8256,  8288,\n",
       "         8320,  8352,  8384,  8416,  8448,  8480,  8512,  8544,  8576,  8608,\n",
       "         8640,  8672,  8704,  8736,  8768,  8800,  8832,  8864,  8896,  8928,\n",
       "         8960,  8992,  9024,  9056,  9088,  9120,  9152,  9184,  9216,  9248,\n",
       "         9280,  9312,  9344,  9376,  9408,  9440,  9472,  9504,  9536,  9568,\n",
       "         9600,  9632,  9664,  9696,  9728,  9760,  9792,  9824,  9856,  9888,\n",
       "         9920,  9952,  9984, 10016, 10048, 10080, 10112, 10144, 10176, 10208,\n",
       "        10240, 10272, 10304, 10336, 10368, 10400, 10432, 10464, 10496, 10528,\n",
       "        10560, 10592, 10624, 10656, 10688, 10720, 10752, 10784, 10816, 10848,\n",
       "        10880, 10912, 10944, 10976, 11008, 11040, 11072, 11104, 11136, 11168,\n",
       "        11200, 11232, 11264, 11296, 11328, 11360, 11392, 11424, 11456, 11488,\n",
       "        11520, 11552, 11584, 11616, 11648, 11680, 11712, 11744, 11776, 11808,\n",
       "        11840, 11872, 11904, 11936, 11968, 12000, 12032, 12064, 12096, 12128,\n",
       "        12160, 12192, 12224, 12256, 12288, 12320, 12352, 12384, 12416, 12448,\n",
       "        12480, 12512, 12544, 12576, 12608, 12640, 12672, 12704, 12736, 12768,\n",
       "        12800, 12832, 12864, 12896, 12928, 12960, 12992, 13024, 13056, 13088,\n",
       "        13120, 13152, 13184, 13216, 13248, 13280, 13312, 13344, 13376, 13408,\n",
       "        13440, 13472, 13504, 13536, 13568, 13600, 13632, 13664, 13696, 13728,\n",
       "        13760, 13792, 13824, 13856, 13888, 13920, 13952, 13984, 14016, 14048,\n",
       "        14080, 14112, 14144, 14176, 14208, 14240, 14272, 14304, 14336, 14368,\n",
       "        14400, 14432])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a7bfb",
   "metadata": {},
   "source": [
    "### Important Methods and functions\n",
    "#### Workflow:\n",
    "##### 1. We take an input batch from our training set on every iteration of the loop.\n",
    "##### 2. We then run those through our model \n",
    "##### 3. compute the loss from the expected output \n",
    "##### 4. compute the gradients at every layer, through backpropogation.\n",
    "##### 5. Finally, Use those gradients to perform the adjustment of the weights and bias\n",
    "\n",
    "\n",
    "#### 1. optimizer.zero_grad() \n",
    "It turns out that the calculated gradients accumulate by default. if we didn’t zero the gradients at the end of the batch’s iteration, the next batch would have to deal with this batch’s gradients\n",
    "We use zero_grad() to make sure they are reset to zero after we’re done with our loop\n",
    "#### 2. loss.backward()\n",
    "To compute the gradients, we call the loss.backward() method on the model\n",
    "#### 3. Optimizer\n",
    "###### Specify the type of Optimizer: SGD, Adam, RMSProp, Adagrad\n",
    "###### optimizer.step():\n",
    "Updates the parameters This should be called once the gradients for every neuron have been computed by invoking the loss.backward()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d9340",
   "metadata": {},
   "source": [
    "| Number | Step name | What does it do? | Code example |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| 1 | Forward pass | The model goes through all of the training data once, performing its `forward()` function calculations. | `model(x_train)` |\n",
    "| 2 | Calculate the loss | The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are. | `loss = loss_fn(y_pred, y_train)` | \n",
    "| 3 | Zero gradients | The optimizers gradients are set to zero (they are accumulated by default) so they can be recalculated for the specific training step. | `optimizer.zero_grad()` |\n",
    "| 4 | Perform backpropagation on the loss | Computes the gradient of the loss with respect for every model parameter to be updated  (each parameter with `requires_grad=True`). This is known as **backpropagation**, hence \"backwards\".  | `loss.backward()` |\n",
    "| 5 | Update the optimizer (**gradient descent**) | Update the parameters with `requires_grad=True` with respect to the loss gradients in order to improve them. | `optimizer.step()` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f6780a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0\n",
      "epoch =  1\n",
      "epoch =  2\n",
      "epoch =  3\n",
      "epoch =  4\n",
      "epoch =  5\n",
      "epoch =  6\n",
      "epoch =  7\n",
      "epoch =  8\n",
      "epoch =  9\n",
      "epoch =  10\n",
      "epoch =  11\n",
      "epoch =  12\n",
      "epoch =  13\n",
      "epoch =  14\n",
      "epoch =  15\n",
      "epoch =  16\n",
      "epoch =  17\n",
      "epoch =  18\n",
      "epoch =  19\n"
     ]
    }
   ],
   "source": [
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    print(\"epoch = \", epoch)\n",
    "    model.train()\n",
    "    for start in batch_start:\n",
    "            # take a batch\n",
    "        \n",
    "        X_batch = X_train[start:start+batch_size]\n",
    "        y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "            # update weights\n",
    "        optimizer.step()\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    #model.eval -> model.train(mode = \"false\")\n",
    "    #model.train(mode = \"true\") -> model.train()\n",
    "    \n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cb340ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.92\n",
      "RMSE: 0.96\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# restore model and return best accuracy\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f17a4b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 3.7714e-01,  1.5971e-02, -2.0707e-01, -1.1569e-01, -1.8699e-01,\n",
       "                       -2.6116e-02,  1.7829e-01, -3.6978e-01],\n",
       "                      [-1.2352e-01,  2.6976e-01,  1.0020e-01, -2.4690e-01, -1.5549e-01,\n",
       "                       -3.3664e-01, -2.6560e-01, -4.1974e-02],\n",
       "                      [ 1.4775e-01,  3.4136e-01, -9.6206e-02,  3.1159e-01,  2.1973e-01,\n",
       "                       -1.1178e-02,  2.6602e-01, -2.7486e-01],\n",
       "                      [ 1.3330e-01,  1.7281e-01, -1.1906e-01, -2.9414e-01, -2.3479e-01,\n",
       "                       -1.8674e-01, -7.1625e-02,  2.6830e-01],\n",
       "                      [-2.2476e-01, -6.3609e-02,  2.1294e-01,  7.0835e-02, -3.6250e-01,\n",
       "                       -7.9187e-02, -3.0405e-01, -2.2493e-01],\n",
       "                      [ 1.1758e-01,  1.7886e-02,  1.0034e-01, -2.0559e-01, -5.7700e-04,\n",
       "                        3.1114e-01, -2.7431e-01,  1.2748e-01],\n",
       "                      [ 4.7664e-01,  2.6252e-01,  2.0889e-01,  1.5212e-01,  8.4660e-02,\n",
       "                       -1.5280e-02,  3.0766e-01, -2.4885e-01],\n",
       "                      [ 1.0848e-01,  1.1640e-01, -1.0566e-01,  4.4616e-03,  7.6120e-03,\n",
       "                        9.2416e-02, -7.0605e-04, -3.2144e-01],\n",
       "                      [ 8.7118e-01, -5.2962e-02,  4.7224e-01,  3.8197e-01,  1.8551e-02,\n",
       "                       -4.6928e-01, -2.6419e-02,  7.6998e-02],\n",
       "                      [-5.9173e-03, -3.3232e-01, -2.0683e-01,  2.2845e-01,  1.5142e-01,\n",
       "                        3.3117e-02, -2.4908e-01,  3.3769e-01],\n",
       "                      [ 2.9564e-01, -3.0916e-01, -3.2609e-01,  3.1624e-01, -1.6618e-01,\n",
       "                       -2.9843e-01,  3.0380e-02,  2.8922e-01],\n",
       "                      [-2.7621e-01, -1.8406e-01,  2.7770e-01,  1.0550e-01, -1.7340e-01,\n",
       "                       -2.8972e-01,  1.2631e-01, -1.6562e-01],\n",
       "                      [ 2.3785e-02,  3.3546e-01,  1.4962e-01, -2.1322e-01, -2.6309e-01,\n",
       "                       -2.9538e-02,  2.5588e-01,  6.6743e-02],\n",
       "                      [-9.7415e-02,  8.7957e-02,  2.2446e-01, -2.8060e-01, -2.6140e-01,\n",
       "                       -3.1653e-01,  1.7242e-01,  2.6811e-01],\n",
       "                      [ 1.2361e-01,  2.9502e-02,  2.2487e-01, -2.6177e-01, -3.4226e-01,\n",
       "                       -3.7318e-01,  2.1813e-01,  1.5453e-01],\n",
       "                      [-1.5886e-01,  2.1592e-01,  2.0610e-01,  2.8315e-01, -3.3312e-01,\n",
       "                        2.2723e-01, -1.5170e-01,  3.2925e-01],\n",
       "                      [ 2.4681e-01, -1.7295e-01,  1.4178e-01, -3.0134e-01,  8.2610e-02,\n",
       "                        6.3220e-02, -4.3877e-02,  2.1024e-01],\n",
       "                      [ 2.2187e-01,  2.7396e-01,  2.7454e-01, -2.5022e-01,  2.3966e-01,\n",
       "                       -3.7760e-02, -3.2824e-01,  2.3920e-01],\n",
       "                      [-9.8963e-01,  2.6219e-01, -4.8735e-01, -2.4898e-01,  6.1623e-03,\n",
       "                        3.1187e-02,  1.2117e-01, -2.8778e-01],\n",
       "                      [-2.9349e-01, -2.8136e-01, -4.0197e-01, -2.2633e-01,  2.3830e-01,\n",
       "                       -2.0490e-01, -6.9773e-02, -1.7795e-01],\n",
       "                      [-1.6086e-01, -1.2165e-01,  1.2253e-01, -2.9335e-01,  1.1454e-01,\n",
       "                        2.7962e-01, -2.1936e-01,  1.8784e-01],\n",
       "                      [-3.2470e-01,  2.9463e-01,  2.9318e-01, -2.5126e-01, -1.4688e-01,\n",
       "                       -8.2091e-02,  8.3023e-02, -2.1525e-01],\n",
       "                      [-4.3505e-02, -1.3822e-01,  3.2834e-01,  4.7980e-02,  1.7726e-01,\n",
       "                       -1.6497e-01, -3.2243e-01,  2.5287e-01],\n",
       "                      [ 1.6617e-01,  1.8241e-01,  2.5817e-01, -1.7114e-01, -3.4521e-01,\n",
       "                        3.1472e-01, -1.8932e-01,  2.8336e-01]])),\n",
       "             ('0.bias',\n",
       "              tensor([-0.1150,  0.2104, -0.2839, -0.2502,  0.2324,  0.0584, -0.1056, -0.0689,\n",
       "                       0.2330, -0.2380,  0.0550, -0.1077,  0.0314,  0.2428, -0.0867,  0.2149,\n",
       "                      -0.2910,  0.0577, -0.0901,  0.0791,  0.1026,  0.0141,  0.1538,  0.2088])),\n",
       "             ('2.weight',\n",
       "              tensor([[-0.2737,  0.1221, -0.0556, -0.0952,  0.0949,  0.1781,  0.1290,  0.1215,\n",
       "                       -0.0437,  0.1125,  0.1285, -0.0946,  0.0044,  0.1318,  0.0837, -0.0007,\n",
       "                        0.1650,  0.1250, -0.1570, -0.1701, -0.1004, -0.0033, -0.0937,  0.0548],\n",
       "                      [ 0.1472, -0.0023,  0.0891,  0.1640,  0.2117,  0.2090,  0.0874,  0.0291,\n",
       "                        0.0296, -0.0855,  0.0095,  0.2150, -0.0742, -0.0658,  0.0838, -0.1137,\n",
       "                       -0.1521,  0.0338,  0.0766,  0.1322,  0.1113,  0.1534,  0.0609, -0.0792],\n",
       "                      [ 0.0683, -0.1596,  0.0573, -0.1828,  0.0637, -0.0038, -0.1347, -0.1439,\n",
       "                       -0.1550,  0.1152,  0.0954,  0.0744,  0.1077,  0.1153,  0.1895, -0.0630,\n",
       "                        0.0506, -0.0197,  0.1162,  0.0523,  0.0939, -0.1586, -0.0593, -0.0582],\n",
       "                      [ 0.1142, -0.1344,  0.0621,  0.0667,  0.1399,  0.0962, -0.1524,  0.1998,\n",
       "                        0.0382, -0.0008, -0.0699, -0.1866,  0.0063,  0.1225,  0.0224, -0.0268,\n",
       "                       -0.0890,  0.1340,  0.0017, -0.0272, -0.0191, -0.0570, -0.0611, -0.1953],\n",
       "                      [-0.0602,  0.0541, -0.0010,  0.1303, -0.1543, -0.0723, -0.0228, -0.0674,\n",
       "                       -0.1311,  0.1076,  0.0803,  0.0004,  0.0570, -0.0464, -0.1610, -0.0348,\n",
       "                        0.1663, -0.2016, -0.0330, -0.1255,  0.2024, -0.1975,  0.0617, -0.1757],\n",
       "                      [-0.1713, -0.0591, -0.0910, -0.1388, -0.2086, -0.2128,  0.1705,  0.1113,\n",
       "                       -0.2549,  0.0117,  0.1092, -0.0070,  0.1559, -0.1143,  0.0260,  0.0746,\n",
       "                        0.0617,  0.0398,  0.2068, -0.1537, -0.0038, -0.1667,  0.1631, -0.1315],\n",
       "                      [ 0.1577, -0.1883, -0.1016,  0.0005,  0.0322,  0.1034, -0.0063,  0.2316,\n",
       "                       -0.0170,  0.1703,  0.1758, -0.1577,  0.0452,  0.1394, -0.1990,  0.0030,\n",
       "                       -0.1753, -0.1455,  0.0829, -0.0189,  0.1416, -0.1728,  0.1805, -0.1415],\n",
       "                      [-0.0127, -0.1238,  0.0477,  0.1627, -0.0919,  0.2227,  0.1713,  0.1281,\n",
       "                        0.2673, -0.0547, -0.2018, -0.0589,  0.2468,  0.1467,  0.0260,  0.0846,\n",
       "                        0.1904,  0.0787, -0.0037,  0.1071, -0.0535, -0.0899,  0.1963,  0.0769],\n",
       "                      [ 0.0908,  0.1719, -0.1459,  0.1573, -0.1944,  0.0709,  0.1624, -0.1910,\n",
       "                        0.0934, -0.1852, -0.1120,  0.0557, -0.2303,  0.1321,  0.1593,  0.0211,\n",
       "                       -0.1946,  0.0324,  0.0869, -0.1668,  0.0593, -0.0355, -0.0735, -0.1347],\n",
       "                      [ 0.0725, -0.0325, -0.1839,  0.0746, -0.1638,  0.0805, -0.0327,  0.1415,\n",
       "                       -0.1289,  0.0799, -0.0199,  0.0232, -0.1973,  0.1041,  0.0422, -0.0832,\n",
       "                        0.1111,  0.0218,  0.2117,  0.1114, -0.0069, -0.0659,  0.1097,  0.1202],\n",
       "                      [-0.0976,  0.1481,  0.0941,  0.1575,  0.0205, -0.1117, -0.0818, -0.0233,\n",
       "                       -0.1074,  0.0029, -0.0389, -0.0890,  0.0981,  0.1782, -0.0866, -0.0616,\n",
       "                        0.1737, -0.0208, -0.0635, -0.1279,  0.0009, -0.0912,  0.1849,  0.1580],\n",
       "                      [-0.0884,  0.0073,  0.0292,  0.1383,  0.0191, -0.1413, -0.1835,  0.0514,\n",
       "                       -0.1522,  0.0023, -0.1610,  0.0775, -0.1545,  0.0263, -0.1079, -0.1684,\n",
       "                       -0.1661,  0.0357, -0.0321,  0.1698,  0.0951,  0.1228, -0.0959,  0.0611]])),\n",
       "             ('2.bias',\n",
       "              tensor([ 0.1208, -0.0073, -0.0121, -0.0995,  0.0180,  0.1147,  0.0881, -0.1285,\n",
       "                       0.1211, -0.0451,  0.0349,  0.0658])),\n",
       "             ('4.weight',\n",
       "              tensor([[ 0.1374,  0.2531, -0.1310, -0.2963, -0.0125,  0.0369, -0.0790, -0.1289,\n",
       "                       -0.0391,  0.1135, -0.1685,  0.2206],\n",
       "                      [ 0.1222,  0.1560,  0.2486,  0.0756,  0.0774,  0.2309, -0.3064,  0.0277,\n",
       "                        0.1051, -0.0417,  0.0796, -0.0100],\n",
       "                      [ 0.0584, -0.1718, -0.2874, -0.0420, -0.0757, -0.2279,  0.1844, -0.0718,\n",
       "                        0.2649, -0.2318,  0.1861,  0.0880],\n",
       "                      [ 0.1142, -0.0397,  0.0514,  0.2586,  0.1189, -0.0064, -0.0881, -0.0185,\n",
       "                        0.2097, -0.0808,  0.1241, -0.0803],\n",
       "                      [-0.2026,  0.1920, -0.1869, -0.0214,  0.0651, -0.0898,  0.1739,  0.2382,\n",
       "                       -0.0718, -0.2655,  0.2162, -0.1215],\n",
       "                      [ 0.1204, -0.1043,  0.0699, -0.1564, -0.2646, -0.1737, -0.1120,  0.2342,\n",
       "                        0.1362,  0.0043,  0.1259,  0.0464]])),\n",
       "             ('4.bias',\n",
       "              tensor([-0.1858, -0.2778, -0.1584, -0.1601, -0.1159,  0.0383])),\n",
       "             ('6.weight',\n",
       "              tensor([[-0.1032, -0.3598, -0.1391, -0.2309,  0.4083, -0.1821]])),\n",
       "             ('6.bias', tensor([-0.1244]))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a5139e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e99ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
